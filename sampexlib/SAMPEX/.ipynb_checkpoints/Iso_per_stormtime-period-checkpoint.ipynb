{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math as m\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "from SAMPEX_functions import read_counts as read\n",
    "from SAMPEX_functions import mb_finder, read_days, mb_magnitude, iso_calculator, OrbAtt_augment_loop\n",
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "import string\n",
    "import datetime\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining files\n",
    "storms = np.array(['1993047-1993053', '1993067-1993069', '1993070-1993071', '1993093-1993099', '1993127-1993133', '1993254-1993260', \\\n",
    "          '1993280-1993286', '1993306-1993312', '1993335-1993340'])\n",
    "\n",
    "bad_storms = np.array(['1993127-1993133', '1993280-1993286', '1993335-1993340'])\n",
    "\n",
    "for bad in bad_storms:\n",
    "    storms = storms[storms != bad]\n",
    "\n",
    "# reading in mag indices\n",
    "# define mag indices data\n",
    "directory = 'E:\\SAMPEX_Data\\\\'\n",
    "file = 'mag_indices_1993.txt'\n",
    "mag_indices = pd.read_csv(directory + file, header = None, delimiter='\\s+')\n",
    "\n",
    "# define day, hr, min, AE, and Dst\n",
    "ind_day = np.array(mag_indices[1])\n",
    "ind_hr = np.array(mag_indices[2])\n",
    "ind_min = np.array(mag_indices[3])\n",
    "t_ind = ind_day*3600*24 + ind_hr*3600 + ind_min*60\n",
    "\n",
    "AE = np.array(mag_indices[4])\n",
    "AE_max = np.max(AE)\n",
    "Dst = np.array(mag_indices[5])\n",
    "\n",
    "# find _ hr average of the AE indices\n",
    "bin_size = 3              # in hours\n",
    "\n",
    "AE_series = pd.Series(AE)\n",
    "AE_perhrs = np.array(AE_series.rolling(bin_size*12, center=True).mean())\n",
    "\n",
    "# defining month\n",
    "month_list = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "# code is specific for year 1993\n",
    "OrbAtt_names = np.array(['OrbAtt_secofyear_1993001-1993012.txt', 'OrbAtt_secofyear_1993013-1993039.txt', 'OrbAtt_secofyear_1993040-1993066.txt', \\\n",
    "                         'OrbAtt_secofyear_1993067-1993093.txt', 'OrbAtt_secofyear_1993094-1993120.txt', 'OrbAtt_secofyear_1993121-1993147.txt', \\\n",
    "                         'OrbAtt_secofyear_1993148-1993174.txt', 'OrbAtt_secofyear_1993175-1993201.txt', 'OrbAtt_secofyear_1993202-1993228.txt', \\\n",
    "                         'OrbAtt_secofyear_1993229-1993255.txt', 'OrbAtt_secofyear_1993256-1993282.txt', 'OrbAtt_secofyear_1993283-1993309.txt', \\\n",
    "                         'OrbAtt_secofyear_1993310-1993336.txt', 'OrbAtt_secofyear_1993337-1993363.txt', 'OrbAtt_secofyear_1993364-1993365.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from storm 1993047-1993053 ...\n",
      "Extracting data from storm 1993067-1993069 ...\n",
      "Extracting data from storm 1993070-1993071 ...\n",
      "Extracting data from storm 1993093-1993099 ...\n",
      "Extracting data from storm 1993254-1993260 ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-bb47c2008263>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[0mt_storm_BG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_storm_BG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_AE_BG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mAE_storm_BG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAE_storm_BG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAE_BG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[0mt_MB_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_MB_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_storm_MB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mappend\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(arr, values, axis)\u001b[0m\n\u001b[0;32m   4743\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4744\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4745\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4747\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iso_MB_prestorm_list = np.array([])\n",
    "iso_MB_mainphase_list = np.array([])\n",
    "iso_MB_recovery_list = np.array([])\n",
    "iso_BG_prestorm_list = np.array([])\n",
    "iso_BG_mainphase_list = np.array([])\n",
    "iso_BG_recovery_list = np.array([])\n",
    "\n",
    "t_MB_list = np.array([])\n",
    "AE_MB_list = np.array([])\n",
    "iso_MB_AE_list = np.array([])\n",
    "t_BG_list = np.array([])\n",
    "AE_BG_list = np.array([])\n",
    "iso_BG_AE_list = np.array([])\n",
    "\n",
    "for storm in storms:\n",
    "    print(f'Extracting data from storm {storm} ...')\n",
    "    # defining file\n",
    "    year = int(storm[0:4])\n",
    "    start_day = int(storm[4:7])\n",
    "    end_day = int(storm[12:])\n",
    "    num_days = end_day - start_day + 1\n",
    "    \n",
    "    iso_MB_storm = np.array([])\n",
    "    iso_BG_storm = np.array([])\n",
    "    t_MB_storm = np.array([])\n",
    "    t_BG_storm = np.array([])\n",
    "    for day_of_year in np.arange(start_day, end_day+1):\n",
    "        # name the day\n",
    "        if len(str(day_of_year)) == 1:\n",
    "            file = 'hhrr' + str(year) + '00' + str(day_of_year) + '.txt'\n",
    "        elif len(str(day_of_year)) == 2:\n",
    "            file = 'hhrr' + str(year) + '0' + str(day_of_year) + '.txt'\n",
    "        elif len(str(day_of_year)) == 3:\n",
    "            file = 'hhrr' + str(year) + str(day_of_year) + '.txt'\n",
    "\n",
    "        # reading in electron counts files:\n",
    "        t_electrons, r1, r2, r3, r4 = read(str(year) + '_data\\\\' + file)\n",
    "\n",
    "        # reading in orbit/attitude data file\n",
    "        OrbAtt_mask = []\n",
    "        for i in np.arange(len(OrbAtt_names)):\n",
    "            OrbAtt_mask.append(day_of_year >= int(OrbAtt_names[i][21:24]) and day_of_year <= int(OrbAtt_names[i][29:32]))\n",
    "        \n",
    "        OA_file = OrbAtt_names[OrbAtt_mask][0]\n",
    "    \n",
    "        directory = 'E:\\SAMPEX_Data\\\\' + str(year) + '_data\\\\'\n",
    "        OrbAtt_file = pd.read_csv(directory + OA_file, names = ['day', 'hr', 'min', 'sec', 'GEO_Radius', 'GEO_Long', 'GEO_Lat', 'Altitude', \n",
    "                                                            'L_Shell', 'MLT', 'SAA_Flag', 'Pitch', 'zenith', 'azimuth', 'Att_Flag'], sep = '\\s+', header = 70)\n",
    "    \n",
    "        # Augment OrbAtt data to fit counts data\n",
    "        t_OrbAtt, LS_OrbAtt, MLT_OrbAtt, P_OrbAtt, Lat_OrbAtt, Long_OrbAtt, R_OrbAtt, t_electrons, r1, r2, r3, r4 = OrbAtt_augment_loop(t_electrons, r1, r2, r3, r4, OrbAtt_file, day_of_year)\n",
    "\n",
    "\n",
    "        ############## mask for spatial/temporal regions ##############\n",
    "        \n",
    "        mask = (np.abs(90 - P_OrbAtt) >= 50) & (LS_OrbAtt >= 3) & (LS_OrbAtt <= 8)\n",
    "        t_OrbAtt = t_OrbAtt[mask]; LS_OrbAtt = LS_OrbAtt[mask]; MLT_OrbAtt = MLT_OrbAtt[mask];\n",
    "        P_OrbAtt = P_OrbAtt[mask]; Lat_OrbAtt = Lat_OrbAtt[mask]; Long_OrbAtt = Long_OrbAtt[mask];\n",
    "        R_OrbAtt = R_OrbAtt[mask]; t_electrons = t_electrons[mask]; r1 = r1[mask]; r2 = r2[mask]; r3 = r3[mask]; r4 = r4[mask]\n",
    "\n",
    "        ###############################################################\n",
    "    \n",
    "    \n",
    "        # find microburst times and N_100, SSD1, SSD4 counts using algorithm\n",
    "        t_microburst, N_100_microburst, r1_microburst, r4_microburst, mb_index, MB_mask, N_100, A_500 = mb_finder(t_electrons, r1, r2, r3, r4)\n",
    "\n",
    "        # create background counts mask\n",
    "        BG_mask = ~MB_mask\n",
    "\n",
    "        # calculation of the isotropy indices of electron counts\n",
    "        iso_indices_MB = iso_calculator(r1[MB_mask], r4[MB_mask])\n",
    "        iso_indices_BG = iso_calculator(r1[BG_mask], r4[BG_mask])\n",
    "    \n",
    "        # find the OrbAtt and magnetic index microburst and backgound parameters\n",
    "        if len(mb_index) > 0:\n",
    "            t_OrbAtt_MB = t_OrbAtt[mb_index]\n",
    "            t_MB = t_OrbAtt_MB + day_of_year*3600*24\n",
    "            t_MB_storm = np.append(t_MB_storm, t_MB)\n",
    "            iso_MB_storm = np.append(iso_MB_storm, iso_indices_MB)\n",
    "        \n",
    "        t_OrbAtt_BG = t_OrbAtt[BG_mask]\n",
    "        t_BG = t_OrbAtt_BG + day_of_year*3600*24\n",
    "        t_BG_storm = np.append(t_BG_storm, t_BG)\n",
    "        iso_BG_storm = np.append(iso_BG_storm, iso_indices_BG)\n",
    "    \n",
    "    # mask indices for correct storm time period\n",
    "    t_storm = (ind_hr*3600 + ind_min*60)[(ind_day >= start_day) & (ind_day <= end_day)]\n",
    "    Dst_storm = Dst[(ind_day >= start_day) & (ind_day <= end_day)]\n",
    "    \n",
    "    # find _ hr average of the Dst indices\n",
    "    bin_size = 3              # in hours\n",
    "    interval = 24*num_days    # in hours\n",
    "\n",
    "    t_perhrs = np.arange(0, interval*12, bin_size*12)\n",
    "    index_perhrs = np.arange(bin_size*12-1, interval*12, bin_size*12)\n",
    "\n",
    "    Dst_series = pd.Series(Dst_storm)\n",
    "    Dst_perhrs = np.array(Dst_series.rolling(bin_size*12, center=False).min())[index_perhrs]\n",
    "    \n",
    "    # Isotropy-Dst study\n",
    "    # categorize Dst indices\n",
    "    t_max = t_perhrs[Dst_perhrs == np.max(Dst_perhrs)]; t_Dmax = [t_max] if isinstance(t_max, int) else t_max\n",
    "    t_min = t_perhrs[Dst_perhrs == np.min(Dst_perhrs)]; t_Dmin = [t_min] if isinstance(t_min, int) else t_min\n",
    "    \n",
    "    t_Dmax_sec = t_Dmax[0]*300 + start_day*3600*24\n",
    "    t_Dmin_sec = t_Dmin[0]*300 + start_day*3600*24\n",
    "\n",
    "    # define stormtime regions\n",
    "    iso_MB_prestorm = iso_MB_storm[t_MB_storm <= t_Dmax_sec]\n",
    "    iso_BG_prestorm = iso_BG_storm[t_BG_storm <= t_Dmax_sec]\n",
    "    \n",
    "    iso_MB_mainphase = iso_MB_storm[(t_MB_storm >= t_Dmax_sec) & (t_MB_storm <= t_Dmin_sec)]\n",
    "    iso_BG_mainphase = iso_BG_storm[(t_BG_storm >= t_Dmax_sec) & (t_BG_storm <= t_Dmin_sec)]\n",
    "    \n",
    "    iso_MB_recovery = iso_MB_storm[t_MB_storm >= t_Dmin_sec]\n",
    "    iso_BG_recovery = iso_BG_storm[t_BG_storm >= t_Dmin_sec]\n",
    "    \n",
    "    # collect in epoch array\n",
    "    iso_MB_prestorm_list = np.append(iso_MB_prestorm_list, iso_MB_prestorm)\n",
    "    iso_MB_mainphase_list = np.append(iso_MB_mainphase_list, iso_MB_mainphase)\n",
    "    iso_MB_recovery_list = np.append(iso_MB_recovery_list, iso_MB_recovery)\n",
    "    \n",
    "    iso_BG_prestorm_list = np.append(iso_BG_prestorm_list, iso_BG_prestorm)\n",
    "    iso_BG_mainphase_list = np.append(iso_BG_mainphase_list, iso_BG_mainphase)\n",
    "    iso_BG_recovery_list = np.append(iso_BG_recovery_list, iso_BG_recovery)\n",
    "\n",
    "    # Isotropy-AE study\n",
    "    # Align isotropy and AE values\n",
    "    t_storm_MB = np.array([])\n",
    "    AE_storm_MB = np.array([])\n",
    "    for t in t_MB_storm:\n",
    "        day = m.ceil(t/(3600*24))-1\n",
    "        sec_of_day = (t-day*3600*24)\n",
    "        hr = sec_of_day/3600\n",
    "    \n",
    "        if sec_of_day % 3600 != 0:\n",
    "            hr_round = m.ceil(hr)-1\n",
    "            minute = sec_of_day/60 - hr_round*60\n",
    "            if minute % 5 != 0:\n",
    "                five_min = (m.ceil(minute/5)-1)*5\n",
    "            elif minute % 5 == 0:\n",
    "                five_min = int(minute)\n",
    "\n",
    "        elif sec_of_day % 3600 == 0:\n",
    "            hr_round = int(hr)\n",
    "            minute = 0\n",
    "            five_min = 0\n",
    "            \n",
    "        if hr_round == 24:\n",
    "            day_new = day + 1\n",
    "            hr_round = 0\n",
    "            t_AE_MB = t_ind[(ind_day == day_new) & (ind_hr == hr_round) & (ind_min == five_min)]\n",
    "            AE_MB = AE_perhrs[(ind_day == day_new) & (ind_hr == hr_round) & (ind_min == five_min)]\n",
    "        \n",
    "        elif hr_round != 24:\n",
    "            t_AE_MB = t_ind[(ind_day == day) & (ind_hr == hr_round) & (ind_min == five_min)]\n",
    "            AE_MB = AE_perhrs[(ind_day == day) & (ind_hr == hr_round) & (ind_min == five_min)]\n",
    "    \n",
    "        t_storm_MB = np.append(t_storm_MB, t_AE_MB)\n",
    "        AE_storm_MB = np.append(AE_storm_MB, AE_MB)\n",
    "\n",
    "    t_storm_BG = np.array([])\n",
    "    AE_storm_BG = np.array([])\n",
    "    for t in t_BG_storm:\n",
    "        day = m.ceil(t/(3600*24))-1\n",
    "        sec_of_day = (t-day*3600*24)\n",
    "        hr = sec_of_day/3600\n",
    "    \n",
    "        if sec_of_day % 3600 != 0:\n",
    "            hr_round = m.ceil(hr)-1\n",
    "            minute = sec_of_day/60 - hr_round*60\n",
    "            if minute % 5 != 0:\n",
    "                five_min = (m.ceil(minute/5)-1)*5\n",
    "            elif minute % 5 == 0:\n",
    "                five_min = int(minute)\n",
    "\n",
    "        elif sec_of_day % 3600 == 0:\n",
    "            hr_round = int(hr)\n",
    "            minute = 0\n",
    "            five_min = 0\n",
    "            \n",
    "        if hr_round == 24:\n",
    "            day_new = day + 1\n",
    "            hr_round = 0\n",
    "            t_AE__BG = t_ind[(ind_day == day_new) & (ind_hr == hr_round) & (ind_min == five_min)]\n",
    "            AE_BG = AE_perhrs[(ind_day == day_new) & (ind_hr == hr_round) & (ind_min == five_min)]\n",
    "        \n",
    "        elif hr_round != 24:\n",
    "            t_AE_BG = t_ind[(ind_day == day) & (ind_hr == hr_round) & (ind_min == five_min)]\n",
    "            AE_BG = AE_perhrs[(ind_day == day) & (ind_hr == hr_round) & (ind_min == five_min)]\n",
    "    \n",
    "        t_storm_BG = np.append(t_storm_BG, t_AE_BG)\n",
    "        AE_storm_BG = np.append(AE_storm_BG, AE_BG)\n",
    "    \n",
    "    t_MB_list = np.append(t_MB_list, t_storm_MB)\n",
    "    AE_MB_list = np.append(AE_MB_list, AE_storm_MB)\n",
    "    iso_MB_AE_list = np.append(iso_MB_AE_list, iso_MB_storm)\n",
    "    \n",
    "    t_BG_list = np.append(t_BG_list, t_storm_BG)\n",
    "    AE_BG_list = np.append(AE_BG_list, AE_storm_BG)\n",
    "    iso_BG_AE_list = np.append(iso_BG_AE_list, iso_BG_storm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(AE))\n",
    "print(len(AE_perhrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average mb iso vs storm phases\n",
    "labels = np.array(['Initial Phase', 'Main Phase', 'Recovery Phase'])\n",
    "labels_x = np.array([1.0,2.0,3.0])\n",
    "\n",
    "iso_MB_avgs_Dst = np.array([np.nanmean(iso_MB_prestorm_list), np.nanmean(iso_MB_mainphase_list), np.nanmean(iso_MB_recovery_list)])\n",
    "iso_MB_std_Dst = np.array([np.nanstd(iso_MB_prestorm_list), np.nanstd(iso_MB_mainphase_list), np.nanstd(iso_MB_recovery_list)])\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.title(f'Average Microburst Isotropy vs Stormtime Phases', fontsize = 15)\n",
    "plt.scatter(labels_x, iso_MB_avgs_Dst, c='royalblue', s = 60, zorder=3)\n",
    "plt.errorbar(labels_x, iso_MB_avgs_Dst, yerr = iso_MB_std_Dst, fmt='none', elinewidth = 2.0, capsize=5, ecolor = 'grey', zorder=2)\n",
    "plt.xlim(0, np.max(labels_x)+1.0)\n",
    "plt.xticks(ticks=labels_x, labels=labels, fontsize=12)\n",
    "plt.ylim(0,1.1)\n",
    "plt.ylabel('Isotropy Index', fontsize=14)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# calculate median mb iso vs storm phases\n",
    "labels = np.array(['Initial Phase', 'Main Phase', 'Recovery Phase'])\n",
    "labels_x = np.array([1.0,2.0,3.0])\n",
    "\n",
    "iso_MB_med_Dst = np.array([np.nanmedian(iso_MB_prestorm_list), np.nanmedian(iso_MB_mainphase_list), np.nanmedian(iso_MB_recovery_list)])\n",
    "iso_MB_75error_Dst = np.array([\n",
    "    np.nanpercentile(iso_MB_prestorm_list, 75) - iso_MB_med_Dst[0],\n",
    "    np.nanpercentile(iso_MB_mainphase_list, 75) - iso_MB_med_Dst[1],\n",
    "    np.nanpercentile(iso_MB_recovery_list, 75) - iso_MB_med_Dst[2]\n",
    "])\n",
    "iso_MB_25error_Dst = np.array([\n",
    "    iso_MB_med_Dst[0] - np.nanpercentile(iso_MB_prestorm_list, 25),\n",
    "    iso_MB_med_Dst[1] - np.nanpercentile(iso_MB_mainphase_list, 25),\n",
    "    iso_MB_med_Dst[2] - np.nanpercentile(iso_MB_recovery_list, 25)\n",
    "])\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.title(f'Median Microburst Isotropy vs Stormtime Phases', fontsize = 15)\n",
    "plt.scatter(labels_x, iso_MB_med_Dst, c='royalblue', s = 60, zorder=3)\n",
    "plt.errorbar(labels_x, iso_MB_med_Dst, yerr = np.array([iso_MB_25error_Dst, iso_MB_75error_Dst]), fmt='none', \\\n",
    "             elinewidth = 2.0, capsize=5, ecolor = 'grey', zorder=2)\n",
    "plt.xlim(0, np.max(labels_x)+1.0)\n",
    "plt.xticks(ticks=labels_x, labels=labels, fontsize=12)\n",
    "plt.ylim(0,1.1)\n",
    "plt.ylabel('Isotropy Index', fontsize=14)\n",
    "plt.grid(axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average bg iso vs storm phases\n",
    "labels = np.array(['Initial Phase', 'Main Phase', 'Recovery Phase'])\n",
    "labels_x = np.array([1.0,2.0,3.0])\n",
    "\n",
    "iso_BG_avgs_Dst = np.array([np.nanmean(iso_BG_prestorm_list), np.nanmean(iso_BG_mainphase_list), np.nanmean(iso_BG_recovery_list)])\n",
    "iso_BG_std_Dst = np.array([np.nanstd(iso_BG_prestorm_list), np.nanstd(iso_BG_mainphase_list), np.nanstd(iso_BG_recovery_list)])\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.title(f'Average Background Isotropy vs Stormtime Phases', fontsize = 15)\n",
    "plt.scatter(labels_x, iso_BG_avgs_Dst, c='sandybrown', s = 60, zorder=3)\n",
    "plt.errorbar(labels_x, iso_BG_avgs_Dst, yerr = iso_BG_std_Dst, fmt='none', elinewidth = 2.0, capsize=5, ecolor = 'grey', zorder=2)\n",
    "plt.xlim(0, np.max(labels_x)+1)\n",
    "plt.xticks(ticks=labels_x, labels=labels, fontsize=12)\n",
    "plt.ylim(0,1.1)\n",
    "plt.ylabel('Isotropy Index', fontsize=14)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# calculate median bg iso vs storm phases\n",
    "labels = np.array(['Initial Phase', 'Main Phase', 'Recovery Phase'])\n",
    "labels_x = np.array([1.0,2.0,3.0])\n",
    "\n",
    "iso_BG_med_Dst = np.array([np.nanmedian(iso_BG_prestorm_list), np.nanmedian(iso_BG_mainphase_list), np.nanmedian(iso_BG_recovery_list)])\n",
    "iso_BG_75error_Dst = np.array([\n",
    "    np.nanpercentile(iso_BG_prestorm_list, 75) - iso_BG_med_Dst[0],\n",
    "    np.nanpercentile(iso_BG_mainphase_list, 75) - iso_BG_med_Dst[1],\n",
    "    np.nanpercentile(iso_BG_recovery_list, 75) - iso_BG_med_Dst[2]\n",
    "])\n",
    "iso_BG_25error_Dst = np.array([\n",
    "    iso_BG_med_Dst[0] - np.nanpercentile(iso_BG_prestorm_list, 25),\n",
    "    iso_BG_med_Dst[1] - np.nanpercentile(iso_BG_mainphase_list, 25),\n",
    "    iso_BG_med_Dst[2] - np.nanpercentile(iso_BG_recovery_list, 25)\n",
    "])\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.title(f'Median Background Isotropy vs Stormtime Phases', fontsize = 15)\n",
    "plt.scatter(labels_x, iso_BG_med_Dst, c='sandybrown', s = 60, zorder=3)\n",
    "plt.errorbar(labels_x, iso_BG_med_Dst, yerr = np.array([iso_BG_25error_Dst, iso_BG_75error_Dst]), fmt='none', elinewidth = 2.0, capsize=5, ecolor = 'grey', zorder=2)\n",
    "plt.xlim(0, np.max(labels_x)+1)\n",
    "plt.xticks(ticks=labels_x, labels=labels, fontsize=12)\n",
    "plt.ylim(0,1.1)\n",
    "plt.ylabel('Isotropy Index', fontsize=14)\n",
    "plt.grid(axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average iso diff vs storm phases\n",
    "iso_diff = iso_MB_avgs_Dst - iso_BG_avgs_Dst\n",
    "error_prop = np.sqrt(iso_MB_std_Dst**2 + iso_BG_std_Dst**2)\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.title(f'Average Isotropy Difference vs Stormtime Phases', fontsize = 15)\n",
    "plt.plot([0,np.max(labels_x)+1], [0,0], color='k', linestyle='-.')\n",
    "plt.scatter(labels_x, iso_diff, c='purple', s = 60, zorder=3)\n",
    "plt.errorbar(labels_x, iso_diff, yerr = error_prop, fmt='none', elinewidth = 2.0, capsize=5, ecolor = 'grey', zorder=2)\n",
    "plt.xlim(0, np.max(labels_x)+1)\n",
    "plt.xticks(ticks=labels_x, labels=labels, fontsize=12)\n",
    "plt.xlabel('AE Index [nT]', fontsize=14)\n",
    "plt.ylim(-0.6,0.6)\n",
    "plt.ylabel('Isotropy Index', fontsize=14)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# calculate average iso diff vs storm phases\n",
    "iso_diff = iso_MB_med_Dst - iso_BG_med_Dst\n",
    "error75_prop = np.sqrt(iso_MB_75error_Dst**2 + iso_BG_75error_Dst**2)\n",
    "error25_prop = np.sqrt(iso_MB_25error_Dst**2 + iso_BG_25error_Dst**2)\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.title(f'Median Isotropy Difference vs Stormtime Phases', fontsize = 15)\n",
    "plt.plot([0,np.max(labels_x)+1], [0,0], color='k', linestyle='-.')\n",
    "plt.scatter(labels_x, iso_diff, c='purple', s = 60, zorder=3)\n",
    "plt.errorbar(labels_x, iso_diff, yerr = np.array([error25_prop, error75_prop]), fmt='none', elinewidth = 2.0, capsize=5, ecolor = 'grey', zorder=2)\n",
    "plt.xlim(0, np.max(labels_x)+1)\n",
    "plt.xticks(ticks=labels_x, labels=labels, fontsize=12)\n",
    "plt.xlabel('AE Index [nT]', fontsize=14)\n",
    "plt.ylim(-0.6,0.6)\n",
    "plt.ylabel('Isotropy Index', fontsize=14)\n",
    "plt.grid(axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average mb iso vs AE\n",
    "AE_max = int(m.ceil(np.max(AE_storm_MB)/100)*100)\n",
    "bin_num = 10\n",
    "AE_bins = np.linspace(0, AE_max, num=bin_num+1)\n",
    "\n",
    "iso_MB_avgs_AE = np.array([])\n",
    "iso_MB_std_AE = np.array([])\n",
    "AE_MB_bin_centers = np.array([])\n",
    "for i in np.arange(len(AE_bins)):\n",
    "    if i == len(AE_bins)-1:\n",
    "        break\n",
    "    print(f'Number of microbursts in {int(AE_bins[i])}-{int(AE_bins[i+1])}'\\\n",
    "          f'AE range: {len(iso_MB_AE_list[(AE_MB_list>=AE_bins[i]) & (AE_MB_list<AE_bins[i+1])])}')\n",
    "    \n",
    "    if len(iso_MB_AE_list[(AE_MB_list>=AE_bins[i]) & (AE_MB_list<AE_bins[i+1])]) >= 100:\n",
    "        iso_MB_avgs_i = np.nanmean(iso_MB_AE_list[(AE_MB_list>=AE_bins[i]) & (AE_MB_list<AE_bins[i+1])])\n",
    "        iso_MB_std_i = np.nanstd(iso_MB_AE_list[(AE_MB_list>=AE_bins[i]) & (AE_MB_list<AE_bins[i+1])])\n",
    "        AE_MB_bin_center_i = np.mean(np.array([AE_bins[i], AE_bins[i+1]]))\n",
    "    \n",
    "    elif len(iso_MB_AE_list[(AE_MB_list>=AE_bins[i]) & (AE_MB_list<AE_bins[i+1])]) < 100:\n",
    "        iso_MB_avgs_i = np.nan\n",
    "        iso_MB_std_i = np.nan\n",
    "        AE_MB_bin_center_i = np.nan\n",
    "    \n",
    "    iso_MB_avgs_AE = np.append(iso_MB_avgs_AE, iso_MB_avgs_i)\n",
    "    iso_MB_std_AE = np.append(iso_MB_std_AE, iso_MB_std_i)\n",
    "    AE_MB_bin_centers = np.append(AE_MB_bin_centers, AE_MB_bin_center_i)\n",
    "    \n",
    "plt.figure(figsize = (10,7))\n",
    "plt.title(f'Average Microburst Isotropy vs AE Index', fontsize = 15)\n",
    "\n",
    "# trendline #\n",
    "idx = np.isfinite(AE_MB_bin_centers) & np.isfinite(iso_MB_avgs_AE)\n",
    "z = np.polyfit(AE_MB_bin_centers[idx], iso_MB_avgs_AE[idx], 1)\n",
    "p = np.poly1d(z)\n",
    "x_p = np.linspace(0, np.max(AE_bins)+np.max(AE_bins)/(2*bin_num))\n",
    "plt.plot(x_p,p(x_p), color='k', linestyle='-', alpha=0.5, zorder=1)\n",
    "# trendline #\n",
    "\n",
    "plt.scatter(AE_MB_bin_centers, iso_MB_avgs_AE, c='royalblue', s = 60, zorder=3)\n",
    "plt.errorbar(AE_MB_bin_centers, iso_MB_avgs_AE, yerr = iso_MB_std_AE, fmt='none', elinewidth = 2.0, capsize=5, ecolor = 'grey', zorder=2)\n",
    "plt.xlim(0, np.max(AE_bins)+np.max(AE_bins)/(2*bin_num))\n",
    "plt.xticks(ticks=AE_bins, fontsize=12)\n",
    "plt.xlabel('AE Index [nT]', fontsize=14)\n",
    "plt.ylim(0,1.1)\n",
    "plt.ylabel('Isotropy Index', fontsize=14)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# calculate median mb iso vs AE\n",
    "AE_max = int(m.ceil(np.max(AE_storm_MB)/100)*100)\n",
    "bin_num = 10\n",
    "AE_bins = np.linspace(0, AE_max, num=bin_num+1)\n",
    "\n",
    "iso_MB_med_AE = np.array([])\n",
    "iso_MB_75error_AE = np.array([])\n",
    "iso_MB_25error_AE = np.array([])\n",
    "AE_MB_bin_centers = np.array([])\n",
    "for i in np.arange(len(AE_bins)):\n",
    "    if i == len(AE_bins)-1:\n",
    "        break\n",
    "    \n",
    "    if len(iso_MB_AE_list[(AE_MB_list>=AE_bins[i]) & (AE_MB_list<AE_bins[i+1])]) >= 100:\n",
    "        iso_MB_med_i = np.nanmedian(iso_MB_AE_list[(AE_MB_list>=AE_bins[i]) & (AE_MB_list<AE_bins[i+1])])\n",
    "        iso_MB_75error_i = np.nanpercentile(iso_MB_AE_list[(AE_MB_list>=AE_bins[i]) & (AE_MB_list<AE_bins[i+1])], 75) - iso_MB_med_i\n",
    "        iso_MB_25error_i = iso_MB_med_i - np.nanpercentile(iso_MB_AE_list[(AE_MB_list>=AE_bins[i]) & (AE_MB_list<AE_bins[i+1])], 25)\n",
    "        AE_MB_bin_center_i = np.mean(np.array([AE_bins[i], AE_bins[i+1]]))\n",
    "    \n",
    "    elif len(iso_MB_AE_list[(AE_MB_list>=AE_bins[i]) & (AE_MB_list<AE_bins[i+1])]) < 100:\n",
    "        iso_MB_med_i = np.nan\n",
    "        iso_MB_75error_i = np.nan\n",
    "        iso_MB_25error_i = np.nan\n",
    "        AE_MB_bin_center_i = np.nan\n",
    "    \n",
    "    iso_MB_med_AE = np.append(iso_MB_med_AE, iso_MB_med_i)\n",
    "    iso_MB_75error_AE = np.append(iso_MB_75error_AE, iso_MB_75error_i)\n",
    "    iso_MB_25error_AE = np.append(iso_MB_25error_AE, iso_MB_25error_i)\n",
    "    AE_MB_bin_centers = np.append(AE_MB_bin_centers, AE_MB_bin_center_i)\n",
    "    \n",
    "plt.figure(figsize = (10,7))\n",
    "plt.title(f'Median Microburst Isotropy vs AE Index', fontsize = 15)\n",
    "\n",
    "# trendline #\n",
    "idx = np.isfinite(AE_MB_bin_centers) & np.isfinite(iso_MB_med_AE)\n",
    "z = np.polyfit(AE_MB_bin_centers[idx], iso_MB_med_AE[idx], 1)\n",
    "p = np.poly1d(z)\n",
    "x_p = np.linspace(0, np.max(AE_bins)+np.max(AE_bins)/(2*bin_num))\n",
    "plt.plot(x_p,p(x_p), color='k', linestyle='-', alpha=0.5, zorder=1)\n",
    "# trendline #\n",
    "\n",
    "plt.scatter(AE_MB_bin_centers, iso_MB_med_AE, c='royalblue', s = 60, zorder=3)\n",
    "plt.errorbar(AE_MB_bin_centers, iso_MB_med_AE, yerr = np.array([iso_MB_25error_AE, iso_MB_75error_AE]), fmt='none', \\\n",
    "             elinewidth = 2.0, capsize=5, ecolor = 'grey', zorder=2)\n",
    "plt.xlim(0, np.max(AE_bins)+np.max(AE_bins)/(2*bin_num))\n",
    "plt.xticks(ticks=AE_bins, fontsize=12)\n",
    "plt.xlabel('AE Index [nT]', fontsize=14)\n",
    "plt.ylim(0,1.1)\n",
    "plt.ylabel('Isotropy Index', fontsize=14)\n",
    "plt.grid(axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average bg iso vs AE\n",
    "AE_max = int(m.ceil(np.max(AE_storm_MB)/100)*100)\n",
    "bin_num = 10\n",
    "AE_bins = np.linspace(0, AE_max, num=bin_num+1)\n",
    "\n",
    "iso_BG_avgs_AE = np.array([])\n",
    "iso_BG_std_AE = np.array([])\n",
    "AE_BG_bin_centers = np.array([])\n",
    "for i in np.arange(len(AE_bins)):\n",
    "    if i == len(AE_bins)-1:\n",
    "        break\n",
    "    print(f'Number of background samples in {int(AE_bins[i])}-{int(AE_bins[i+1])}'\\\n",
    "          f'AE-range: {len(iso_BG_AE_list[(AE_BG_list>=AE_bins[i]) & (AE_BG_list<AE_bins[i+1])])}')\n",
    "    \n",
    "    if len(iso_BG_AE_list[(AE_BG_list>=AE_bins[i]) & (AE_BG_list<AE_bins[i+1])]) >= 100:\n",
    "        iso_BG_avgs_i = np.nanmean(iso_BG_AE_list[(AE_BG_list>=AE_bins[i]) & (AE_BG_list<AE_bins[i+1])])\n",
    "        iso_BG_std_i = np.nanstd(iso_BG_AE_list[(AE_BG_list>=AE_bins[i]) & (AE_BG_list<AE_bins[i+1])])\n",
    "        AE_BG_bin_center_i = np.mean(np.array([AE_bins[i], AE_bins[i+1]]))\n",
    "    \n",
    "    elif len(iso_BG_AE_list[(AE_BG_list>=AE_bins[i]) & (AE_BG_list<AE_bins[i+1])]) < 100:\n",
    "        iso_BG_avgs_i = np.nan\n",
    "        iso_BG_std_i = np.nan\n",
    "        AE_BG_bin_center_i = np.nan\n",
    "    \n",
    "    iso_BG_avgs_AE = np.append(iso_BG_avgs_AE, iso_BG_avgs_i)\n",
    "    iso_BG_std_AE = np.append(iso_BG_std_AE, iso_BG_std_i)\n",
    "    AE_BG_bin_centers = np.append(AE_BG_bin_centers, AE_BG_bin_center_i)\n",
    "    \n",
    "plt.figure(figsize = (10,7))\n",
    "plt.title(f'Average Background Isotropy vs AE Index', fontsize = 15)\n",
    "\n",
    "# trendline #\n",
    "idx = np.isfinite(AE_BG_bin_centers) & np.isfinite(iso_BG_avgs_AE)\n",
    "z = np.polyfit(AE_BG_bin_centers[idx], iso_BG_avgs_AE[idx], 1)\n",
    "p = np.poly1d(z)\n",
    "x_p = np.linspace(0, np.max(AE_bins)+np.max(AE_bins)/(2*bin_num))\n",
    "plt.plot(x_p,p(x_p), color='k', linestyle='-', alpha=0.5, zorder=1)\n",
    "# trendline #\n",
    "\n",
    "plt.scatter(AE_BG_bin_centers, iso_BG_avgs_AE, c='sandybrown', s = 60, zorder=3)\n",
    "plt.errorbar(AE_BG_bin_centers, iso_BG_avgs_AE, yerr = iso_BG_std_AE, fmt='none', elinewidth = 2.0, capsize=5, ecolor = 'grey', zorder=2)\n",
    "plt.xlim(0, np.max(AE_bins)+np.max(AE_bins)/(2*bin_num))\n",
    "plt.xticks(ticks=AE_bins, fontsize=12)\n",
    "plt.xlabel('AE Index [nT]', fontsize=14)\n",
    "plt.ylim(0,1.1)\n",
    "plt.ylabel('Isotropy Index', fontsize=14)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# calculate median bg iso vs AE\n",
    "AE_max = int(m.ceil(np.max(AE_storm_MB)/100)*100)\n",
    "bin_num = 10\n",
    "AE_bins = np.linspace(0, AE_max, num=bin_num+1)\n",
    "\n",
    "iso_BG_med_AE = np.array([])\n",
    "iso_BG_75error_AE = np.array([])\n",
    "iso_BG_25error_AE = np.array([])\n",
    "AE_BG_bin_centers = np.array([])\n",
    "for i in np.arange(len(AE_bins)):\n",
    "    if i == len(AE_bins)-1:\n",
    "        break\n",
    "    \n",
    "    if len(iso_BG_AE_list[(AE_BG_list>=AE_bins[i]) & (AE_BG_list<AE_bins[i+1])]) >= 100:\n",
    "        iso_BG_med_i = np.nanmedian(iso_BG_AE_list[(AE_BG_list>=AE_bins[i]) & (AE_BG_list<AE_bins[i+1])])\n",
    "        iso_BG_75error_i = np.nanpercentile(iso_BG_AE_list[(AE_BG_list>=AE_bins[i]) & (AE_BG_list<AE_bins[i+1])], 75) - iso_BG_med_i\n",
    "        iso_BG_25error_i = iso_BG_med_i - np.nanpercentile(iso_BG_AE_list[(AE_BG_list>=AE_bins[i]) & (AE_BG_list<AE_bins[i+1])], 25)\n",
    "        AE_BG_bin_center_i = np.mean(np.array([AE_bins[i], AE_bins[i+1]]))\n",
    "    \n",
    "    elif len(iso_BG_AE_list[(AE_BG_list>=AE_bins[i]) & (AE_BG_list<AE_bins[i+1])]) < 100:\n",
    "        iso_BG_med_i = np.nan\n",
    "        iso_BG_75error_i = np.nan\n",
    "        iso_BG_25error_i = np.nan\n",
    "        AE_BG_bin_center_i = np.nan\n",
    "    \n",
    "    iso_BG_med_AE = np.append(iso_BG_med_AE, iso_BG_med_i)\n",
    "    iso_BG_75error_AE = np.append(iso_BG_75error_AE, iso_BG_75error_i)\n",
    "    iso_BG_25error_AE = np.append(iso_BG_25error_AE, iso_BG_25error_i)\n",
    "    AE_BG_bin_centers = np.append(AE_BG_bin_centers, AE_BG_bin_center_i)\n",
    "    \n",
    "plt.figure(figsize = (10,7))\n",
    "plt.title(f'Median Background Isotropy vs AE Index', fontsize = 15)\n",
    "\n",
    "# trendline #\n",
    "idx = np.isfinite(AE_BG_bin_centers) & np.isfinite(iso_BG_med_AE)\n",
    "z = np.polyfit(AE_BG_bin_centers[idx], iso_BG_med_AE[idx], 1)\n",
    "p = np.poly1d(z)\n",
    "x_p = np.linspace(0, np.max(AE_bins)+np.max(AE_bins)/(2*bin_num))\n",
    "plt.plot(x_p,p(x_p), color='k', linestyle='-', alpha=0.5, zorder=1)\n",
    "# trendline #\n",
    "\n",
    "plt.scatter(AE_BG_bin_centers, iso_BG_med_AE, c='sandybrown', s = 60, zorder=3)\n",
    "plt.errorbar(AE_BG_bin_centers, iso_BG_med_AE, yerr = np.array([iso_BG_25error_AE, iso_BG_75error_AE]), fmt='none', \\\n",
    "             elinewidth = 2.0, capsize=5, ecolor = 'grey', zorder=2)\n",
    "plt.xlim(0, np.max(AE_bins)+np.max(AE_bins)/(2*bin_num))\n",
    "plt.xticks(ticks=AE_bins, fontsize=12)\n",
    "plt.xlabel('AE Index [nT]', fontsize=14)\n",
    "plt.ylim(0,1.1)\n",
    "plt.ylabel('Isotropy Index', fontsize=14)\n",
    "plt.grid(axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average iso diff vs AE\n",
    "iso_diff = iso_MB_avgs_AE - iso_BG_avgs_AE\n",
    "error_prop = np.sqrt(iso_MB_std_AE**2 + iso_BG_std_AE**2)\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.title(f'Average Isotropy Difference vs AE Index', fontsize = 15)\n",
    "\n",
    "# trendline #\n",
    "idx = np.isfinite(AE_MB_bin_centers) & np.isfinite(iso_diff)\n",
    "z = np.polyfit(AE_MB_bin_centers[idx], iso_diff[idx], 1)\n",
    "p = np.poly1d(z)\n",
    "x_p = np.linspace(0, np.max(AE_bins)+np.max(AE_bins)/(2*bin_num))\n",
    "plt.plot(x_p,p(x_p), color='k', linestyle='-', alpha=0.5, zorder=1)\n",
    "# trendline #\n",
    "\n",
    "plt.plot([0,np.max(AE_bins)+np.max(AE_bins)/(2*bin_num)], [0,0], color='k', linestyle='-.')\n",
    "plt.scatter(AE_MB_bin_centers, iso_diff, c='purple', s = 60, zorder=3)\n",
    "plt.errorbar(AE_MB_bin_centers, iso_diff, yerr = iso_BG_std_AE, fmt='none', elinewidth = 2.0, capsize=5, ecolor = 'grey', zorder=2)\n",
    "plt.xlim(0, np.max(AE_bins)+np.max(AE_bins)/(2*bin_num))\n",
    "plt.xticks(ticks=AE_bins, fontsize=12)\n",
    "plt.xlabel('AE Index [nT]', fontsize=14)\n",
    "plt.ylim(-0.5,0.5)\n",
    "plt.ylabel('Isotropy Index', fontsize=14)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# calculate median iso diff vs AE\n",
    "iso_diff = iso_MB_med_AE - iso_BG_med_AE\n",
    "error75_prop = np.sqrt(iso_MB_75error_AE**2 + iso_BG_75error_AE**2)\n",
    "error25_prop = np.sqrt(iso_MB_25error_AE**2 + iso_BG_25error_AE**2)\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.title(f'Median Isotropy Difference vs AE Index', fontsize = 15)\n",
    "\n",
    "# trendline #\n",
    "idx = np.isfinite(AE_MB_bin_centers) & np.isfinite(iso_diff)\n",
    "z = np.polyfit(AE_MB_bin_centers[idx], iso_diff[idx], 1)\n",
    "p = np.poly1d(z)\n",
    "x_p = np.linspace(0, np.max(AE_bins)+np.max(AE_bins)/(2*bin_num))\n",
    "plt.plot(x_p,p(x_p), color='k', linestyle='-', alpha=0.5, zorder=1)\n",
    "# trendline #\n",
    "\n",
    "plt.plot([0,np.max(AE_bins)+np.max(AE_bins)/(2*bin_num)], [0,0], color='k', linestyle='-.')\n",
    "plt.scatter(AE_MB_bin_centers, iso_diff, c='purple', s = 60, zorder=3)\n",
    "plt.errorbar(AE_MB_bin_centers, iso_diff, yerr = np.array([error25_prop, error75_prop]), fmt='none', \\\n",
    "             elinewidth = 2.0, capsize=5, ecolor = 'grey', zorder=2)\n",
    "plt.xlim(0, np.max(AE_bins)+np.max(AE_bins)/(2*bin_num))\n",
    "plt.xticks(ticks=AE_bins, fontsize=12)\n",
    "plt.xlabel('AE Index [nT]', fontsize=14)\n",
    "plt.ylim(-0.6,0.6)\n",
    "plt.ylabel('Isotropy Index', fontsize=14)\n",
    "plt.grid(axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
